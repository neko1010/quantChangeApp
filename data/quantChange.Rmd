---
title: "quantChange"
output: html_document
date: "2025-04-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

** All code and output for manuscript titled "Time series analyses provide a low-cost and scalable way to assess restoration outcomes from satellite data" **

Packages and variable definition
```{r packages and variables, echo=FALSE}
###################################
# Authors: Nicholas Kolarik, Carolyn Koehn, Erik Nati-Johnson, Juan C Rojas Lucero
# Last modified: 04/22/25
###################################

## Load all libraries
library(bfast) ##BFAST
library(terra)
library(gtools)
library(sf)
library(bcp) ## Bayesian Change Point v4.0.3
library(Rbeast) ## Bayesian Estimator of Abrupt and Seasonal Trends
library(CausalImpact) ## Bayesian Structural Time Series
library(zoo)


## read the CSV data
data = read.csv('yankee.csv')

## Insert a row for July 2019
data[nrow(data) +1,] = c("July 1, 2019", NA)

## sort the df
data = data[order(as.Date(data$system.time_start, format = "%b %e, %Y")),]
rownames(data) = 1:nrow(data)

## cast to numeric dtype
data$mesic = as.numeric(data$mesic)

## function to interpolate with vals from same month in preceding and following years
replace_na_with_mean <- function(df) {
  for (i in 1:ncol(df)) {
    na_indices <- which(is.na(df[, i]))
    for (j in na_indices) {
      if (j == 1) {
        df[j, i] <- df[j + 4, i]
      } else if (j == nrow(df)) {
        df[j, i] <- df[j - 4, i]
      } else {
        df[j, i] <- mean(c(df[j - 4, i], df[j + 4, i]))
      }
    }
  }
  return(df)
}

## apply the interpolation function to fill NAs
data_fill = replace_na_with_mean(data)

## import .tif as raster
ras = rast('Yankee.tif')
plot(ras)
crs(ras)

## import .shp for restoration AOI
aoi = st_read('yankee.shp')

## insert an entire month of NAs for July 2019
july19 = rast(ras[[1]], vals = NA, names = c('1_1_040029_201907_mesic'))
july19

## add this empty rast to the full stack
ras = c(ras, july19)
ras

## add time stamps to each
names = names(ras)
dates = sapply(names, function(name){
  as.Date(paste0(unlist(strsplit(name, "_"))[4],"01"),"%Y%m%d")
})

## sort by dates
dates_sort = order(dates)
dates_sorted = as.Date(dates[dates_sort])
ras_sort = ras[[dates_sort]]

## apply the sorted dates to the 'time' property of the raster
terra::time(ras_sort)= dates_sorted

## double check times
time(ras_sort)

## years for later
years_vect_no2016 = c(rep(2004,4), rep(2005,4), rep(2006,4), rep(2007,4), 
                      rep(2008,4),rep(2009,4), rep(2010,4),rep(2011,4),
                      rep(2012,4),rep(2013,4),rep(2014,4),rep(2015,4),
                      rep(2017,4),rep(2018,4),rep(2019,4),rep(2020,4))

```


BCP plots

``` {r BCP reduced, echo = FALSE}
## include a 'year' variable
#data_fill$year = as.numeric(format(as.Date(data_fill$system.time_start, format = "%b %e, %Y"), "%Y"))
data_fill$year = format(as.Date(data_fill$system.time_start, format = "%b %e, %Y"), "%Y")

## univariate
results_bcp = bcp(data_fill$mesic)
plot(results_bcp, main = "BCP output - Mesic probabilities of change",
     xlab = "Date", xaxlab = data_fill$year ) ## FIGURE 3

summary(results_bcp)

## Multivariate - use PDSI as a predictor with time

## data with drought index predictor
pdsi = read.csv('pdsi_Yankee.csv') ## common 

## remove 2016 to have corresponding values with the time series
pdsi$year = as.numeric(format(as.Date(pdsi$system.time_start, format = "%b %e, %Y"), "%Y"))
pdsi_no2016 = subset(pdsi, year != 2016)

data_multiv = cbind(data_fill, pdsi_no2016$pdsi)
results_bcp_multiv = bcp(data_multiv$mesic, data_multiv$`pdsi_no2016$pdsi`)
plot(results_bcp_multiv, main = "BCP output - Mesic probabilities of change - Multivariate", 
     xlab = "Date", xaxlab = data_fill$year ) ## FIGURE S1

summary(results_bcp_multiv)

```
BCP pixels

```{r BCP pixels}

# convert to array
array_input <- as.array(ras_sort)
#array_input
#array_input[,,58] #view any month in the time series to verify, in this case the NAs for July 2019
#now we have an array with matching dimensions of the data we want to apply
#still need to impute data for NA values

# Function to impute missing values in a time series. Using the mean of the same month in the previous and following year
impute_time_series_by_year <- function(ts) {
  # Find indices of missing values in the time series
  na_idx <- which(is.na(ts))
  
  for (i in na_idx) {
    # Determine the indices corresponding to the same month in the previous and next year.
    # (4 months per year so shift by 4)
    i_prev <- i - 4
    i_next <- i + 4
    
    values_to_avg <- c()
    
    # Check if the previous year index is within bounds and not NA.
    if (i_prev >= 1 && !is.na(ts[i_prev])) {
      values_to_avg <- c(values_to_avg, ts[i_prev])
    }
    
    # Check if the next year index is within bounds and not NA.
    if (i_next <= length(ts) && !is.na(ts[i_next])) {
      values_to_avg <- c(values_to_avg, ts[i_next])
    }
    
    # If we have at least one valid neighbor, compute the mean.
    if (length(values_to_avg) > 0) {
      ts[i] <- mean(values_to_avg)
    }
    # Otherwise, the NA remains.
  }
  
  return(ts)
}

# Loop through each pixel in the spatial grid and apply the imputation
n_rows <- dim(array_input)[1]
n_cols <- dim(array_input)[2]

for (row in 1:n_rows) {
  for (col in 1:n_cols) {
    array_input[row, col, ] <- impute_time_series_by_year(array_input[row, col, ])
  }
}

# Check if any NAs remain
#sum(is.na(array_input))  # Should return 0 if all were successfully imputed

#check dimensions
#dim(array_input)

#get dimensions and number of pixels
n_rows <- dim(array_input)[1]
n_cols <- dim(array_input)[2]
n_pixels <- n_rows * n_cols

##### Producing Raster representing time of greatest probability of change #########

# Preallocate a vector to hold the "time of max posterior probability" for each pixel
max_prob_time <- numeric(n_pixels)

# Process each pixel: run bcp on its time series and extract the time index with highest posterior probability
pixel_idx <- 1
for (row in 1:n_rows) {
  for (col in 1:n_cols) {
    ts <- array_input[row, col, ]  # Extract the time series (length 64) for the pixel
    res <- bcp(ts)                # Run Bayesian Change Point analysis
    # Extract the time step (index) with the maximum posterior probability
    max_time <- which.max(res$posterior.prob)
    max_prob_time[pixel_idx] <- max_time
    pixel_idx <- pixel_idx + 1
  }
}

# Use your raster template "ras" to create the output raster.
# Since "ras" has 64 bands, we'll use the first band as a template for the output.
ras_out <- ras[[1]]
values(ras_out) <- max_prob_time
names(ras_out) <- "max_posterior_time"

# Replace raster values: Extract the current values (indices 1 to 64) from ras_out.
#current_indices <- values(ras_out)
# Map each index to its corresponding year using the lookup vector.
#new_year_values <- years_vect_no2016[current_indices]

#ras_out_dates = subst(ras_out, from = c(1:64), to = as.factor(years_vect_no2016))
ras_out= subst(ras_out, from = c(1:64), to = as.factor(years_vect_no2016))

# Replace the raster's values.
#values(ras_out) <- new_year_values

# Plot the resulting raster
#plot(ras_out, main = "Time of Greatest Posterior Probability")

##### Producing Raster representing magnitude of greatest probability of change ##########

# Preallocate a vector to store the maximum posterior probability value for each pixel
max_prob_value <- numeric(n_pixels)

# Loop through each pixel (each spatial location)
pixel_idx <- 1
for (row in 1:n_rows) {
  for (col in 1:n_cols) {
    ts <- array_input[row, col, ]  # Extract time series (length = 64) for the pixel
    res <- bcp(ts)                # Run Bayesian Change Point analysis
    # Extract the maximum posterior probability value
    max_val <- max(res$posterior.prob, na.rm = TRUE)
    max_prob_value[pixel_idx] <- max_val
    pixel_idx <- pixel_idx + 1
  }
}

# Use the existing raster template "ras" (which has 64 bands) 
# Use one band as a template to create an output single-band raster.
ras_out2 <- ras[[1]]
values(ras_out2) <- max_prob_value
names(ras_out2) <- "max_posterior_value"

# Plot the output raster
plot(ras_out2, main = "Magnitude of Greatest Posterior Probability")


##### Producing Raster representing magnitude of greatest probability of change ##########
# Preallocate a vector to store the largest magnitude of change in posterior means for each pixel
max_change_posterior_mean <- numeric(n_pixels)

pixel_idx <- 1
for (row in 1:n_rows) {
  for (col in 1:n_cols) {
    ts <- array_input[row, col, ]   # Extract the 64-point time series for the pixel
    res <- bcp(ts)                  # Run bcp on the time series
    
    # Compute the absolute differences in posterior means between successive time points
    diff_post_means <- abs(diff(res$posterior.mean))
    
    # Find the maximum magnitude of change in posterior means
    max_diff <- max(diff_post_means, na.rm = TRUE)
    
    max_change_posterior_mean[pixel_idx] <- max_diff
    pixel_idx <- pixel_idx + 1
  }
}

# Create an output raster using the existing template 'ras'
# We use the first band of 'ras' as a template for a new single-band raster.
ras_out3 <- ras[[1]]
values(ras_out3) <- max_change_posterior_mean
names(ras_out3) <- "max_change_posterior_mean"

# Plot the output raster
#plot(ras_out3, main = "Largest Magnitude of Change in Posterior Means")


## a 3 panel plot - FIGURE S1
parameterBCP <- par(mfrow = c(1,3))
## Time of highest probability of change
parameterBCP <- plot(ras_out, main = "A")
#parameterBCP <- plot(ras_out_dates, main = "A")
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)
## sep 2020
parameterBCP <- plot(ras_out2, main = "B")
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)

## Magnitude change
parameterBCP <- plot(ras_out3, main = "C")
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)

```
BFAST

```{r BFAST reduced, echo = FALSE}
## create a time series object
data_ts = ts(data_fill$mesic, frequency = 4)

## Plot the time series
plot(data_ts)

## apply the BFAST function
fit = bfast(data_ts, h = 0.15, season = "harmonic")

## test the sensitivity to the prop of observations used to detect breakpoint; < 0.5
fit_05 = bfast(data_ts, h = 0.05, season = "harmonic")
fit_25 = bfast(data_ts, h = 0.25, season = "harmonic")
fit_35 = bfast(data_ts, h = 0.35, season = "harmonic")
fit_45 = bfast(data_ts, h = 0.45, season = "harmonic")

## plot the output 
years_bfast = c(2004, 2005, 2006, 2007, 2008, 2009, 2010,
                2011, 2012, 2013, 2014, 2015, 2017, 2018, 2019, 2020)
plot(fit, ANOVA = T, main = "BFAST output", xaxt = "n") ## FIGURE 5 OMIT INDICES SOMEHOW
axis(1, at = 1:16, labels = years_bfast)
```

BFAST pixels

```{r BFAST pixels, echo=FALSE}
## Function to apply the bfast function and return outputs of interest
xbfast <- function(data) {  
  mesic <- ts(data, frequency=4, start=2004) 
  result <- bfast(mesic, season="harmonic", decomp = 'stlplus')
  niter <- length(result$output)
  out <- result$output[[niter]]
  bp <- out$Wt.bp ##breakpoint of the seasonality component
  st <- out$St #the seasonality component
  st_a <- st[1:bp] #seasonality until the breakpoint 
  st_b <- st[bp:64] #hard coded end-point 
  st_amin <- min(st_a)
  st_amax <- max(st_a)
  st_bmin <- min(st_b)
  st_bmax <- max(st_b)
  st_adif <- st_amax - st_amin
  st_bdif <- st_bmax - st_bmin
  st_dif <- st_bdif - st_adif
  Magni<-result$Magnitude #magnitude of the biggest change detected in the trend component
  Timing<-result$Time #timing of the biggest change detected in the trend component
  return(c(st_dif,bp,Magni,Timing)) 
}

## apply bfast to every pixel using app()
bfast_output <- app(ras_sort, fun=xbfast)
## plot all outputs
plot(bfast_output)

## a 4 panel plot Figure S3
parameter <- par(mfrow = c(1,4))
## sep 2004
parameter <- plot(ras_sort[[4]], main = "A", range = c(0, 0.6))
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)
## sep 2020
parameter <- plot(ras_sort[[64]], main = "B", range = c(0, 0.6))
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)
## Individual BFAST outputs
diff <- subset(bfast_output, 1)
time <- subset(bfast_output, 2)
magn <- subset(bfast_output, 3)
magn_time <- subset(bfast_output, 4)

## Magnitude change
parameter <- plot(magn, main = "C")
plot(st_geometry(aoi), border = "black", add = T, lwd = 3)
## substitute dates for indices
## Time of greatest magnitude change
magn_time_dates = subst(magn_time, from = c(1:64), to = years_vect_no2016)
#parameter <- plot(magn.time.dates, main = "Panel D\nTime of largest magnitude\n of change in trend")
parameter <- plot(magn_time_dates, main = "D")
plot(st_geometry(aoi), border = "black", add = T, lwd = 3) ## LWD 3 for all!
```


Bayesian Estimator of Abrupt and Seasonal Trends (BEAST)

``` {r BEAST}
results_beast = beast(data_fill$mesic, start = as.Date('2004-6-1'), deltat = "3 months", dump.ci = T)
plot(results_beast, interactive = F) ## FIGURE 7

## Embrace the NAs! insert some more for 2016
data_2016 = cbind(c("Jun 1, 2016", "July 1, 2016", "Aug 1, 2016", "Sep 1, 2016"),
                  c(rep(NA,4)))

colnames(data_2016) = c("system.time_start", "mesic")
data_NAs = rbind(data, data_2016)
data_NAs$date = as.Date(data_NAs$system.time_start, format = "%b %e, %Y")
data_NAs = data_NAs[order(data_NAs$date),]
data_ts_NA = ts(data_NAs$mesic, frequency = 4, start = 2004)

## missing data
results_beast_na = beast(as.numeric(data_ts_NA), start = as.Date('2004-1-1'), deltat = "3 months") 
plot(results_beast_na, interactive = F) ## FIGURE S2 missing data leads to higher probability of negative slopes, and an extra breakpoint estimated in the trend

## Parameter tweaking tests ##
## Uniform precision priors
results_beast_na_unifPrec = beast(as.numeric(data_ts_NA), start = as.Date('2004-1-1'), deltat = "3 months", precPriorType = 'uniform') 
plot(results_beast_na_unifPrec, interactive = F) ## FIGURE S3
## Component precision priors
results_beast_na_compPrec = beast(as.numeric(data_ts_NA), start = as.Date('2004-1-1'), deltat = "3 months", precPriorType = 'componentwise') 
plot(results_beast_na_compPrec, interactive = F, cex.lab = 1) ## Exploratory only - NO FIGURE IN PAPER

```

BEAST pixels

``` {r BEAST pixels}

# apply BEAST to 3D time series
# "pseudo-BFAST" method
beast_output <- beast123(Y = array_input,
                         metadata = 
                           list(whichDimIsTime = 3, # the layer dimension (3rd dimension) corresponds to time
                                startTime = as.Date('2004-1-1'),
                                deltaTime = "3 months", # time between data points
                                period = "1 year"), # length of seasonal period (we expect a yearly cycle)
                         season = 'harmonic',
                         mcmc = list(seed = 101), # set seed for +/- reproducible results
                         extra = list(dumpInputData = TRUE)) # return the data used by BEAST to illustrate what is occurring under the hood

# irregular time series method
beast_output_irreg <- beast123(Y = array_input,
                         metadata = 
                           list(whichDimIsTime = 3, # the layer dimension (3rd dimension) corresponds to time
                                time = time(ras_sort), # since time series is irregular, provide times here
                                startTime = time(ras_sort)[1],
                                deltaTime = "1 month", # time between data points
                                period = "1 year", # length of seasonal period (we expect a yearly cycle) 
                                sorder.minmax = 2), # we expect only one annual max/min
                         season = 'harmonic',
                         mcmc = list(seed = 101), # set seed for +/- reproducible results
                         extra = list(dumpInputData = TRUE)) # return the data used by BEAST (the regular time series generated from our irregular time series) to illustrate what is occurring under the hood

#############################################
# Reading the output

## Our data had 11 columns and 26 rows in the raster, with 69 time points
## BEAST can fill in an irregular time series, adding NAs for missing months
## Here is an example of the time series generated for a pixel:
print(beast_output$data[15,7,])

## see summary plot for one pixel
plot(beast_output, index = c(15, 7))

## irregular for comparison - FIGURE S4
plot(beast_output_irreg, index = c(15, 7))

# Measures of model fit by pixel
# R2
par(mfrow=c(1,2))
plot(rast(beast_output$R2,
          crs=crs(ras_sort),
          extent=ext(ras_sort)), # convert matrix to raster
     main = "R2 of model fit")
# RMSE
plot(rast(beast_output$RMSE,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "RMSE of model fit")

# Time series descriptions
## Number of change points (median over all models)
par(mfrow = c(1,2))
plot(rast(beast_output$trend$ncp_median,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Median number of\ntrend change points")
plot(rast(beast_output$season$ncp_median,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Median number of\nseasonal change points")

## Probability of the median number of change points
get_Pr_for_ncp <- function(ncpPr, ncp) {
  return(ncpPr[[1]][ncp+1])
}

ncpPr_trend_median <- matrix(data = mapply(FUN = get_Pr_for_ncp,
                                           apply(beast_output$trend$ncpPr, MARGIN=c(1,2), list),
                                           beast_output$trend$ncp_median),
                             nrow = nrow(beast_output$trend$ncp_median),
                             ncol = ncol(beast_output$trend$ncp_median),
                             byrow = FALSE)

ncpPr_season_median <- matrix(data = mapply(FUN = get_Pr_for_ncp,
                                           apply(beast_output$season$ncpPr, MARGIN=c(1,2), list),
                                           beast_output$season$ncp_median),
                             nrow = nrow(beast_output$season$ncp_median),
                             ncol = ncol(beast_output$season$ncp_median),
                             byrow = FALSE)
  
par(mfrow = c(1,2))
plot(rast(ncpPr_trend_median,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Probability of\nmedian number of\ntrend change points")
plot(rast(ncpPr_season_median,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Probability of\nmedian number of\nseasonal change points")

## Descriptive stats for largest magnitude of change in trend
get_largest_magn_change_stats <- function(cpAbruptChange, ncp, cpPr, cp) {
  stats.to.return <- c(cpMagn = NA,
                       cpMagnPr = NA,
                       cpMagnTime = NA)
  if(ncp > 0) {
    highest.magn.trend <- which.max(abs(cpAbruptChange[[1]]))
    
    stats.to.return["cpMagn"] <- cpAbruptChange[[1]][highest.magn.trend]
    stats.to.return["cpMagnPr"] <- cpPr[[1]][highest.magn.trend]
    stats.to.return["cpMagnTime"] <- cp[[1]][highest.magn.trend]
  }
  return(stats.to.return)
}

largest_magn_trend_change <- mapply(FUN = get_largest_magn_change_stats,
                 apply(beast_output$trend$cpAbruptChange, MARGIN = c(1,2), list),
                 beast_output$trend$ncp_median,
                 apply(beast_output$trend$cpPr, MARGIN = c(1,2), list),
                 apply(beast_output$trend$cp, MARGIN = c(1,2), list))

### Magnitude of largest trend change
cpMagn_trend <- matrix(data = largest_magn_trend_change["cpMagn",],
                       nrow = nrow(beast_output$trend$cpAbruptChange),
                       ncol = ncol(beast_output$trend$cpAbruptChange),
                       byrow = FALSE)

### Probability of largest trend change
cpMagnProb_trend <- matrix(data = largest_magn_trend_change["cpMagnPr",],
                       nrow = nrow(beast_output$trend$cpAbruptChange),
                       ncol = ncol(beast_output$trend$cpAbruptChange),
                       byrow = FALSE)

### Time of largest trend change
cpMagnTime_trend <- matrix(data = largest_magn_trend_change["cpMagnTime",],
                       nrow = nrow(beast_output$trend$cpAbruptChange),
                       ncol = ncol(beast_output$trend$cpAbruptChange),
                       byrow = FALSE)

### Largest magnitude in trend plots
par(mfrow = c(1,3))  ## FIGURE S4
plot(rast(cpMagn_trend,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     #main = "Panel A\nLargest magnitude\nof change in trend",
     main = "A",
     mar = c(2.6, 4.6, 3.6, 6.6),
     col = viridisLite::viridis(50))
plot(st_geometry(aoi), border="black", lwd = 3, add=T)
plot(rast(cpMagnProb_trend,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     #main = "Panel B\nProbability of largest\nchange magnitude in trend",
     main = "B",
     mar = c(2.6, 4.6, 3.6, 6.6),
     col = viridisLite::viridis(50))
plot(st_geometry(aoi), border="black", lwd = 3, add=T)
plot(as.factor(rast(cpMagnTime_trend,
          crs=crs(ras_sort),
          extent=ext(ras_sort))),
     #main = "Panel C\nTime of largest change\nmagnitude in trend",
     main = "C",
     mar = c(2.6, 4.6, 3.6, 6.6),
     col = viridisLite::viridis(50))
plot(st_geometry(aoi), border="black", lwd = 3, add=T)

## Trend component from all pixels
par(mfrow=c(1,1))
plot(x = beast_output$time,
     xlab = "Date",
     y = beast_output$trend$Y[1,1,],
     ylab = "Time Series Trend",
     type="l", main = "Trend Component for all Pixels",
     ylim = c(0,0.8), col="gray80") # y-limits should be adjusted for your results
apply(beast_output$trend$Y,
      MARGIN = c(1,2),
      function(y) {
        lines(x = beast_output$time,
              y = y, 
              col="gray80")
        return()
      })


## Largest seasonal change magnitude
largest_magn_season_change <- mapply(FUN = get_largest_magn_change_stats,
                                    apply(beast_output$season$cpAbruptChange, MARGIN = c(1,2), list),
                                    beast_output$season$ncp_median,
                                    apply(beast_output$season$cpPr, MARGIN = c(1,2), list),
                                    apply(beast_output$season$cp, MARGIN = c(1,2), list))

### Magnitude of largest seasonal change
cpMagn_season <- matrix(data = largest_magn_season_change["cpMagn",],
                       nrow = nrow(beast_output$season$cpAbruptChange),
                       ncol = ncol(beast_output$season$cpAbruptChange),
                       byrow = FALSE)

### Probability of largest seasonal change
cpMagnProb_season <- matrix(data = largest_magn_season_change["cpMagnPr",],
                           nrow = nrow(beast_output$season$cpAbruptChange),
                           ncol = ncol(beast_output$season$cpAbruptChange),
                           byrow = FALSE)

### Time of largest seasonal change
cpMagnTime_season <- matrix(data = largest_magn_season_change["cpMagnTime",],
                           nrow = nrow(beast_output$season$cpAbruptChange),
                           ncol = ncol(beast_output$season$cpAbruptChange),
                           byrow = FALSE)

### Largest magnitude in season plots
par(mfrow = c(1,3))
plot(rast(cpMagn_season,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Largest magnitude\nof change in season")
plot(rast(cpMagnProb_season,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Probability of\nlargest magnitude\nof change in season")
plot(rast(cpMagnTime_season,
          crs=crs(ras_sort),
          extent=ext(ras_sort)),
     main = "Time of\nlargest magnitude\nof change in season")

## Seasonal component from all pixels
par(mfrow=c(1,1))
plot(x = beast_output$time,
     xlab = "Date",
     y = beast_output$season$Y[1,1,],
     ylab = "Time Series Seasonal",
     type="l", main = "Seasonal Component for all Pixels",
     ylim = c(-0.6,0.6), col="gray80") # y-limits should be adjusted for your results
apply(beast_output$season$Y,
      MARGIN = c(1,2),
      function(y) {
        lines(x = beast_output$time,
              y = y, 
              col="gray80")
        return()
      })
```





Bayesian Structural Time Series (BSTS)

``` {r BSTS}

## Include PDSI as a predictor
data_bsts=  cbind(data_fill$mesic, pdsi_no2016$pdsi)
data_bsts_time =  zoo(cbind(data_fill$mesic, pdsi$pdsi), 
                      as.Date(data_fill$system.time_start,format = "%b %e, %Y")) ## includes missing data period

## define pre and post restoration periods
pre_period = c(1,32)
post_period = c(33, 64)

## with date
pre_period_date = as.Date(c("Jun 1, 2004", "Sep 1,2011"), format = "%b %e, %Y")
post_period_date = as.Date(c("Jun 1, 2012", "Sep 1,2020"), format = "%b %e, %Y")

impact = CausalImpact(data_bsts, pre_period, post_period, model.args = list(nseasons = 4))
impact_time = CausalImpact(data_bsts_time, pre_period_date, post_period_date, 
                           model.args = list(nseasons = 4))

summary(impact) 
summary(impact_time) ## nearly identical results AND includes period of missing data...

plot(impact) ## FIGURE S4
plot(impact_time) ## FIGURE 7

```

BSTS pixels

```{r BSTS pixels}

#I've created the matrix since I need a pdsi value per pixel over time. 
#Considering that PDSI has a value per year over that area, what I made was repeat the values in a matrix. 

ras_df <- as.data.frame(ras_sort)
pdsi_repeated<-(pdsi_no2016$pdsi)
pdsi_matrix <- matrix(rep(pdsi_repeated, each = 286), ncol = length(pdsi_repeated))
# Initialize an empty list to store combined zoo objects
combined_zoo <- list()
all_values <- c()# Initialize an empty vector to store values
ras_df[] <- lapply(seq_along(ras_df), function(i) {
  x <- ras_df[[i]]  # Extract the current column
  # If the entire column is NA, replace it with the mean of the previous and next columns
  if (all(is.na(x))) {
    if (i > 1 & i < ncol(ras_df)) {  
      x[] <- rowMeans(cbind(ras_df[[i - 1]], ras_df[[i + 1]]), na.rm = TRUE)
      print(x[])
    } else if (i == 1) {  # If it's the first column, use only the next column
      x[] <- ras_df[[i + 1]]
    } else if (i == ncol(ras_df)) {  # If it's the last column, use only the previous column
      x[] <- ras_df[[i - 1]]
    }
  } else {
    x[is.na(x)] <- mean(x, na.rm = TRUE)  # Replace individual NAs with the column mean
  }
  
  return(x)
})

####################################################################
#######################
# Combine mesic and pdsi by row
combined_data <- cbind(ras_df, pdsi_matrix)  
#  BSTS function
xbsts <- function(ras_df) {  
  column_mesic <- ras_df[1:64]
  column_pdsi  <- ras_df[65:128]
  combined_zoo <- zoo(cbind(column_mesic, column_pdsi))
  pre.period <- c(1, 32)
  post.period <- c(33, 64)
  impact <-   CausalImpact(combined_zoo, pre.period, post.period, model.args = list(nseasons = 4))
  # Extract predicted values and point effects
  predicted_values <- impact$series$point.pred
  point_effects <- impact$series$point.effect
  
  dataf <- data.frame(predicted_values,point_effects)
  return(dataf)  
}

bsts_output <- (apply(combined_data, 1, xbsts))  

all_point_effects <- list()
all_point_pred <- list()


# Loop over each index (from 1 to 286)
for (i in 1:286) {
  point_effects <- bsts_output[[i]]$point_effects
  point_pred<- bsts_output[[i]]$predicted_values
  point_change <- bsts_output[[i]]$effect
  all_point_effects[[i]] <- point_effects
  all_point_pred[[i]] <- point_pred
  
}

# Convert the list of point_effects into a data frame
point_effects_matrix <- do.call(rbind, all_point_effects)
point_pred_matrix <- do.call(rbind, all_point_pred)

pred <- point_pred_matrix[,64]
point_pred_matrix <- matrix(pred, nrow = nrow(ras_sort), ncol = ncol(ras_sort), byrow = TRUE)
point_pred_raster <- rast(point_pred_matrix)
ext(point_pred_raster) <- ext(ras_sort)
crs(point_pred_raster) <- crs(ras_sort)

effect <- point_effects_matrix[,64]
point_effect_matrix <- matrix(effect, nrow = nrow(ras_sort), ncol = ncol(ras_sort), byrow = TRUE)
point_effect_raster <- rast(point_effect_matrix)
ext(point_effect_raster) <- ext(ras_sort)
crs(point_effect_raster) <- crs(ras_sort)

# Adjust margins to allow space for long titles
par(mfrow = c(1, 3), mar = c(6, 4, 8, 2))  #

# Plot the largest magnitude of change in trend FIGURE 7 
plot(ras_sort[[64]], 
     main = "A", ## Observed 202009
     zlim = c(0, 0.6),  cex.main = 1)
plot(st_geometry(aoi), border="black", lwd = 3, add=T)
plot(point_pred_raster, 
     main = "B",## Counterfactual 202009
     zlim = c(0, 0.6),  cex.main = 1)
plot(st_geometry(aoi), border="black", lwd = 3, add=T)
plot(point_effect_raster, 
     main = "C", ## Difference 
     zlim = c(0, 0.6),
     cex.main = 1)
plot(st_geometry(aoi), border="black", lwd = 3, add=T)
```